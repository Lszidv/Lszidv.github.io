<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://avatars.githubusercontent.com/u/160511559?s=400&u=68ec73daff523efd8652079b221d42e446d01cb6&v=4"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="# Abstract 
### **SeisCLIP: 基于对比学习的地震学基础模型**

- **核心目标**：解决地震学研究中标注数据稀缺和模型区域泛化能力不足的问题。">
<meta property="og:title" content="[Literature reading]SeisCLIP: A Seismology Foundation Model Pre-Trained by Multimodal Data for Multipurpose Seismic Feature Extraction">
<meta property="og:description" content="# Abstract 
### **SeisCLIP: 基于对比学习的地震学基础模型**

- **核心目标**：解决地震学研究中标注数据稀缺和模型区域泛化能力不足的问题。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://Lszidv.github.io/post/%5BLiterature%20reading%5DSeisCLIP-%20A%20Seismology%20Foundation%20Model%20Pre-Trained%20by%20Multimodal%20Data%20for%20Multipurpose%20Seismic%20Feature%20Extraction.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/160511559?s=400&u=68ec73daff523efd8652079b221d42e446d01cb6&v=4">
<title>[Literature reading]SeisCLIP: A Seismology Foundation Model Pre-Trained by Multimodal Data for Multipurpose Seismic Feature Extraction</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>




<body>
    <div id="header">
<h1 class="postTitle">[Literature reading]SeisCLIP: A Seismology Foundation Model Pre-Trained by Multimodal Data for Multipurpose Seismic Feature Extraction</h1>
<div class="title-right">
    <a href="https://Lszidv.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/Lszidv/Lszidv.github.io/issues/35" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><h1>Abstract</h1>
<h3><strong>SeisCLIP: 基于对比学习的地震学基础模型</strong></h3>
<ul>
<li><strong>核心目标</strong>：解决地震学研究中标注数据稀缺和模型区域泛化能力不足的问题。</li>
<li><strong>方法</strong>：
<ul>
<li>1.采用 <strong>对比学习</strong> 进行预训练；2.结合 <strong>Transformer 频谱编码器</strong> 和 <strong>MLP 事件信息编码器</strong>。</li>
</ul>
</li>
<li><strong>优势</strong>：
<ul>
<li>1.适用于<strong>多个地震学任务</strong>（分类、定位、震源机制分析）；2.在<strong>不同区域数据集</strong>上表现优于基线方法；3.仅需少量数据即可微调。</li>
</ul>
</li>
</ul>
<hr>
<h1>1.Introduction</h1>
<h3>** 研究背景**</h3>
<ul>
<li>
<p><strong>机器学习（ML）与深度学习（DL）</strong> 在多个地震学任务中优于传统方法：</p>
<ul>
<li><strong>去噪、震相拾取、地震检测、震源机制分析、地震预测</strong> 等。</li>
</ul>
</li>
<li>
<p><strong>现有方法局限性</strong>：</p>
<ul>
<li><strong>单任务模型</strong> 无法适应数据不足的任务。</li>
<li><strong>迁移学习（TL）</strong> 受限于特定子领域。</li>
<li><strong>基础模型（Foundation Model）</strong> 能提升泛化能力。</li>
</ul>
</li>
<li>
<p><strong>定义</strong>：先 <strong>预训练</strong>，再 <strong>微调（Fine-tuning）</strong>，适应多个下游任务。</p>
</li>
</ul>
<h3><strong>预训练策略</strong></h3>
<ul>
<li><strong>生成式学习</strong>（如 BERT、MAE）：   通过 <strong>遮蔽部分数据</strong> 进行预测。</li>
<li><strong>对比式学习</strong>（如 CLIP）：让匹配样本对靠近，错误样本远离。</li>
</ul>
<h3><strong>地震学基础模型</strong></h3>
<ul>
<li><strong>StorSeismic（BERT-based）</strong> 和 <strong>SFM（MAE-based）</strong> 主要用于 <strong>地震勘探</strong>（2D 数据）。</li>
<li><strong>SeisCLIP（对比学习）</strong>：
<ul>
<li>结合 <strong>地震频谱</strong>（Transformer 编码）和 <strong>事件信息</strong>（MLP 编码）。</li>
<li>采用 <strong>STEAD 数据集</strong> 进行多模态训练。</li>
</ul>
</li>
</ul>
<h3><strong>结论</strong></h3>
<ul>
<li><strong>挑战</strong>：
<ul>
<li>2D 地震模型难适用于 1D 波形。</li>
<li>任务间数据不均衡。</li>
</ul>
</li>
<li><strong>解决方案</strong>：
<ul>
<li><strong>SeisCLIP</strong> 采用 <strong>对比学习</strong> 进行 <strong>多模态预训练</strong>。</li>
<li>结合 <strong>Transformer+MLP</strong> 提取 <strong>地震特征</strong>。</li>
</ul>
</li>
</ul>
<hr>
<h1>2.Methods</h1>
<h3>A. 地震学基础模型的架构</h3>
<h4><strong>1. 研究目标</strong></h4>
<ul>
<li>提出 <strong>SeisCLIP</strong>，采用 <strong>对比学习（Contrastive Learning）</strong> 进行 <strong>预训练</strong>。</li>
<li>解决 <strong>长序列地震波形处理的计算开销问题</strong>，提高模型在 <strong>地震学任务</strong> 中的适用性。</li>
</ul>
<h4><strong>2. 网络架构</strong></h4>
<ul>
<li><strong>双分支编码器</strong>
<ul>
<li><strong>频谱分支（Spectrum Branch）</strong>：
<ul>
<li><strong>STFT 转换地震波形为频谱</strong>，采用 <strong>VIT-small</strong> （图像识别）进行编码。</li>
</ul>
</li>
<li><strong>事件信息分支（Information Branch）</strong>：
<ul>
<li>处理 <strong>P/S 波到时、震源距离等 8 种参数</strong>，并使用 <strong>MLP 进行编码</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4><strong>3. 训练策略</strong></h4>
<ul>
<li><strong>采用频谱表示</strong>，(波形太长)减少计算开销，提高 Transformer 处理地震数据的适用性。</li>
<li><strong>对比学习（Contrastive Learning）</strong>：
<ul>
<li>让模型学习 <strong>匹配正确的频谱与事件信息</strong>，提高泛化能力。</li>
</ul>
</li>
<li><strong>训练样本结构</strong>
<ul>
<li><strong>三通道频谱数据 + 八种事件信息</strong>，分别输入到编码器进行联合训练。</li>
</ul>
</li>
</ul>
<h2><strong>B. 预训练和验证的数据准备</strong></h2>
<ul>
<li>采用 <strong>STEAD 数据集</strong>，包含 <strong>1,030,000 条地震信号</strong> 和 <strong>8 种事件信息</strong>。</li>
<li>训练集：<strong>1,000,000 条</strong>，验证集：<strong>30,000 条</strong>。</li>
</ul>
<p><strong>下游任务数据集</strong></p>
<h3><strong>（1）地震定位（Localization）</strong></h3>
<ul>
<li><strong>数据来源</strong>：日本地震数据，<strong>M &gt; 2</strong>，<strong>包含 2011 年东日本大地震</strong>。</li>
<li><strong>地震站</strong>：NIED Hi-net，<strong>提供高分辨率三分量地震数据</strong>。</li>
<li><strong>数据划分</strong>：
<ul>
<li>训练集：<strong>10,000</strong></li>
<li>验证集：<strong>1,000</strong></li>
<li>测试集：<strong>1,000</strong></li>
</ul>
</li>
</ul>
<h3><strong>（2）震源机制分析（Focal Mechanism Analysis）</strong></h3>
<ul>
<li><strong>数据来源</strong>：日本地震数据，<strong>M &gt; 3</strong>，2011-2016 年，JMA 提供震源机制解。</li>
<li><strong>数据划分</strong>：训练集：<strong>随机划分</strong>，具体信息见 <strong>表 II</strong>。</li>
</ul>
<p><strong>数据预处理</strong></p>
<ul>
<li><strong>所有波形数据</strong> 统一处理：<strong>截取 60 秒片段</strong>；<strong>100 Hz 采样率</strong>；<strong>STFT 转换为时频谱</strong>； <strong>均值-标准差归一化</strong></li>
</ul>
<h2><strong>C. 通过对比学习（Contrastive Learning）预训练 SeisCLIP</strong></h2>
<p><strong>预训练策略</strong></p>
<ul>
<li><strong>目标</strong>：
<ul>
<li><strong>联合训练</strong> 频谱编码器和信息编码器，使其学习 <strong>匹配的地震频谱与事件信息</strong>。</li>
</ul>
</li>
<li><strong>对比学习（Contrastive Learning）</strong>：
<ul>
<li><strong>最大化真实样本对的余弦相似度</strong>。</li>
<li><strong>最小化错误匹配样本对的余弦相似度</strong>（共 N² - N 个错误组合）。</li>
</ul>
</li>
<li><strong>优化策略</strong>：采用 <strong>对称交叉熵损失</strong> 确保训练稳定。</li>
</ul>
<p><strong>训练细节</strong></p>
<ul>
<li><strong>超参数设置</strong>： <strong>学习率（Learning Rate）</strong> = 1e-4； <strong>批量大小（Batch Size）</strong> = 192； <strong>训练轮数（Epochs）</strong> = 100</li>
<li><strong>模型选择</strong>： <strong>第 55 轮的模型在验证集上表现最佳</strong>，被选为最终预训练模型。</li>
<li><strong>模型部署</strong></li>
<li>训练完成后，<strong>SeisCLIP 频谱编码器可直接用于下游任务</strong>：<strong>事件分类</strong>； <strong>地震定位</strong>；<strong>震源机制分析</strong></li>
</ul>
<h2><strong>D. SeisCLIP 在下游任务中的应用</strong></h2>
<p><strong>下游任务</strong>: <strong>事件分类（Event Classification）</strong>;<strong>地震定位（Earthquake Localization）</strong>;<strong>震源机制分析（Focal Mechanism Analysis）</strong></p>
<p><strong>训练策略</strong></p>
<ul>
<li><strong>Fine-Tune</strong>：微调 <strong>预训练的 VIT-small 频谱编码器</strong>。</li>
<li><strong>Frozen</strong>：冻结编码器，只训练任务层。</li>
<li><strong>Scratch</strong>：不使用 SeisCLIP 预训练权重，从零训练。</li>
</ul>
<p><strong>基线模型对比</strong></p>
<ul>
<li><strong>波形模型（Waveform-Based）</strong></li>
<li><strong>频谱模型（Spectrum-Based）</strong></li>
<li><strong>对比 SeisCLIP 频谱编码器与传统方法</strong></li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/user-attachments/assets/8c95c553-55f9-49ea-81b1-e43ec9a9d090"><img src="https://github.com/user-attachments/assets/8c95c553-55f9-49ea-81b1-e43ec9a9d090" alt="Image" style="max-width: 100%;"></a></p>
<hr>
<h1>3.RESULTS</h1>
<p>##<strong>A. 事件分类（Event Classification）</strong></p>
<p><strong>评估方法</strong></p>
<ul>
<li>采用 <strong>一对多（One-vs-All）</strong> 方式评估分类任务。</li>
<li>计算 <strong>ROC 曲线和 AUC 值</strong> 评估分类能力。</li>
</ul>
<p><strong>结果分析</strong></p>
<ul>
<li><strong>Fine-Tune 模型的 AUC 值最高，优于 Frozen 和 Scratch</strong>。</li>
<li><strong>混淆矩阵显示 Fine-Tune 模型分类准确率更高</strong>。</li>
<li><strong>由于 STEAD 预训练数据集中仅有地震数据，Frozen 模型受限，而 Scratch 模型表现更稳定</strong>。</li>
</ul>
<p><strong>泛化能力</strong></p>
<ul>
<li><strong>在 SCSN 二分类任务（地震 vs. 爆炸）中，Fine-Tune 模型的 AUC 最高</strong>，展现了 <strong>SeisCLIP 的优越泛化能力</strong>。</li>
</ul>
<h2><strong>B. 事件定位（Event Location）</strong></h2>
<p><strong>震中距离预测</strong></p>
<ul>
<li><strong>Fine-Tune 模型的震中定位误差更低，优于基线模型</strong>。</li>
<li><strong>图 6(a), (c) 中 SeisCLIP 预测的震中点颜色更亮，表示误差更小</strong>。</li>
<li><strong>Fine-Tune 模型的误差分布更接近零，整体精度更高</strong>。</li>
</ul>
<p><strong>震源深度预测</strong></p>
<ul>
<li><strong>Fine-Tune 模型在震源深度预测中也优于 Frozen 和 Baseline</strong>。</li>
<li><strong>图 6 第三行：Fine-Tune 模型的高亮区域颜色更亮，误差更小</strong>。</li>
<li><strong>Fine-Tune 模型的残差分布最窄，MAE 误差最低</strong>（图 6 第四行）。</li>
</ul>
<p><strong>其他定位因素</strong></p>
<ul>
<li><strong>除了震中距离和深度，SeisCLIP 还优化了经度、纬度和震级估计</strong>（图 7）。</li>
<li><strong>Fine-Tune 模型的误差分布更集中，显示其优越的震级预测能力</strong>。</li>
</ul>
<p><strong>结论</strong></p>
<ul>
<li><strong>SeisCLIP 在地震事件定位任务中的表现显著优于传统基线方法</strong>。</li>
<li><strong>Fine-Tune 版本的泛化能力更强，可用于更广泛的地震学任务</strong>。</li>
</ul>
<h2><strong>C. 震源机制分析（Focal Mechanism Analysis）</strong></h2>
<p><strong>任务定义</strong></p>
<ul>
<li><strong>目标：</strong> 预测地震的震源机制（正断层、逆断层、走滑断层）。</li>
<li><strong>挑战：</strong> 震源机制原本是回归问题（预测 Strike, Dip, Rake），但数据有限，因此转化为分类任务。</li>
<li><strong>输入：</strong> <strong>多台站地震数据</strong>，用于震源机制分类。</li>
<li><strong>输出：</strong> 预测 <strong>正断层（Normal）、逆断层（Reverse）、走滑断层（Strike-Slip）</strong>（见 <strong>图 1(d)</strong>）。</li>
</ul>
<p><strong>评估方法</strong></p>
<ul>
<li><strong>使用 PNW 数据集的分类评估标准</strong>：
<ul>
<li><strong>ROC 曲线（Receiver Operating Characteristic Curve）</strong></li>
<li><strong>AUC 值（Area Under the Curve）</strong></li>
<li><strong>混淆矩阵（Confusion Matrix）</strong></li>
</ul>
</li>
</ul>
<h2><strong>3. 结果分析</strong></h2>
<ul>
<li><strong>ROC 曲线（图 8 第一行）</strong>：
<ul>
<li><strong>SeisCLIP 在所有断层类型上表现最佳</strong>。</li>
<li><strong>Fine-Tune 模型的 AUC 最高</strong>，Frozen 也明显优于 Baseline。</li>
</ul>
</li>
<li><strong>混淆矩阵分析</strong>：
<ul>
<li><strong>Fine-Tune 分类正确率最高</strong>。</li>
<li><strong>Frozen 仍然比 Baseline 强，说明预训练特征有效</strong>。</li>
</ul>
</li>
</ul>
<hr>
<p>##4. DISCUSSION</p>
<h3><strong>1. SeisCLIP 预训练特征分析与可视化</strong></h3>
<p>SeisCLIP 采用 <strong>预训练（Pretraining）+ 微调（Fine-Tuning）</strong> 方式，在多个地震学任务中展现优异性能。<br>
通过 <strong>t-SNE 降维分析</strong>，可视化 <strong>Frozen、Scratch、Fine-Tuned</strong> 三种训练策略的特征分布，以理解模型学习到的特征。</p>
<p><strong>预训练与微调</strong></p>
<ul>
<li><strong>预训练阶段</strong>：
<ul>
<li>在 <strong>STEAD 数据集</strong> 上训练，学习 <strong>地震频谱的基本特征</strong>。</li>
<li>主要学习 <strong>地震事件的基本频谱模式</strong>，但无法精准区分 <strong>爆炸 vs. 地震</strong>。</li>
</ul>
</li>
<li><strong>微调阶段</strong>：
<ul>
<li>在 <strong>PNW、SCSN、日本数据集</strong> 上进一步优化，提高任务适应性和泛化能力。</li>
<li>Fine-Tune 使模型能够更清晰地区分 <strong>地震、爆炸和地表事件</strong>。</li>
</ul>
</li>
</ul>
<p><strong>t-SNE 降维分析</strong></p>
<ul>
<li><strong>t-SNE 主要用于高维特征投影到 2D 空间，便于观察特征聚类情况</strong>。</li>
<li><strong>不同训练策略的特征聚类情况（图 9）</strong>：
<ul>
<li><strong>Frozen 模型</strong>：仅能区分 <strong>地震 vs. 非地震</strong>，但无法区分 <strong>爆炸 vs. 地震</strong>。</li>
<li><strong>Scratch 模型</strong>：特征分布较散乱，类别边界不清晰，未能有效学习地震信号特征。</li>
<li><strong>Fine-Tune 模型</strong>：特征聚类最清晰，类别边界明确，能够精确区分 <strong>地震、爆炸和地表事件</strong>。</li>
</ul>
</li>
</ul>
<h3><strong>2. STFT 参数对 SeisCLIP 模型的影响与计算成本分析</strong></h3>
<p>SeisCLIP 预训练时采用 <strong>短时傅里叶变换（STFT）</strong> 进行地震波形到频谱的转换，不同 STFT 参数对模型分类与定位任务的影响显著。</p>
<p><strong>STFT 设定</strong></p>
<ul>
<li><strong>频率点数</strong>：50</li>
<li><strong>频率范围</strong>：0-50 Hz</li>
<li><strong>时间采样窗口</strong>：
<ul>
<li><strong>120 采样点（适用于分类任务）</strong></li>
<li><strong>600 采样点（适用于定位任务）</strong></li>
</ul>
</li>
</ul>
<p><strong>STFT 参数对任务表现的影响</strong></p>
<ul>
<li><strong>短频谱窗口（120 采样点）</strong>：
<ul>
<li>适用于 <strong>事件分类任务</strong>，因分类任务主要依赖频谱特征而非时间信息。</li>
<li>计算成本低，训练更快。</li>
</ul>
</li>
<li><strong>长频谱窗口（600 采样点）</strong>：
<ul>
<li>适用于 <strong>震中定位任务</strong>，因震中定位依赖 <strong>P-S 波到时信息</strong>。</li>
<li>更长的时间窗口可提供更完整的震相信息，提高定位精度。</li>
</ul>
</li>
</ul>
<h3><strong>2.3 计算成本分析</strong></h3>
<ul>
<li><strong>计算时间对比</strong>：
<ul>
<li><strong>50 × 600 模型训练 100 轮需要 5 天</strong>。</li>
<li><strong>50 × 120 模型训练 100 轮仅需 2 天</strong>。</li>
</ul>
</li>
</ul>
<h3><strong>3. 多台站任务的计算效率与 SeisCLIP 适用性分析</strong></h3>
<p>SeisCLIP 在 <strong>多台站任务</strong> 中计算效率和适用性成为关键因素。</p>
<p><strong>计算效率分析</strong><br>
..<br>
<strong>SeisCLIP 适用性</strong></p>
<ul>
<li><strong>Fine-Tune 模型可扩展至其他任务</strong>：
<ul>
<li><strong>极性判断（Polarity Determination）</strong></li>
<li><strong>事件检测（Event Detection）</strong></li>
<li><strong>峰值地面运动估计（Peak Ground Motion Estimation）</strong>。</li>
</ul>
</li>
<li><strong>泛化能力的挑战</strong>：
<ul>
<li><strong>不同频谱尺寸的任务可能无法直接适配固定频谱尺寸的预训练模型</strong>，影响泛化能力。</li>
<li>例如：
<ul>
<li><strong>分类任务适用小频谱（120 采样点）</strong>。</li>
<li><strong>定位任务适用大频谱（600 采样点）</strong>。<br>
<strong>解决方案</strong></li>
</ul>
</li>
</ul>
</li>
<li><strong>发布三种不同频谱尺寸的预训练模型</strong>，提高适应性，使不同任务可选择合适的模型进行微调。</li>
</ul>
<hr>
<p>##5.CONCLUSION<br>
<strong>SeisCLIP 作为地震学基础模型</strong></p>
<ul>
<li><strong>我们提出了一种基础模型（Foundation Model），用于事件分类、地震定位和震源机制分析。</strong></li>
<li><strong>不同于传统深度学习方法，我们的方法先进行预训练，再进行微调，提高泛化能力。</strong></li>
</ul>
<p><strong>预训练 + 微调的优势</strong></p>
<ul>
<li><strong>预训练阶段</strong>：学习通用的地震信号特征，提高数据利用率。</li>
<li><strong>微调阶段</strong>：在不同任务上优化，使模型适应分类、定位、震源机制分析等任务。</li>
<li><strong>最终效果</strong>：模型在多个任务中均表现优异，超越基线模型。</li>
</ul>
<p><strong>多区域数据集测试</strong></p>
<ul>
<li><strong>通过在 PNW、SCSN、日本等数据集上测试，验证 SeisCLIP 的泛化能力。</strong></li>
<li><strong>结果表明，SeisCLIP 在多个数据集上表现优于基线模型，证明了其适用性。</strong></li>
</ul>
<p><strong>SeisCLIP 的未来潜力</strong></p>
<ul>
<li><strong>SeisCLIP 作为通用模型，可扩展到更多地震学任务，如极性判断、事件检测、峰值地面运动估计等。</strong></li>
<li><strong>为下一代地震学深度学习模型的发展提供了蓝图，推动地震学智能分析的发展。</strong></li>
</ul>
<hr>
<h2><strong>附录 A：评估指标（Evaluation Metrics）</strong></h2>
<h3><strong>1. 二分类任务的评估方法</strong></h3>
<p>对于 <strong>二分类任务（如地震 vs. 爆炸）</strong>，我们采用 <strong>ROC 曲线（Receiver Operating Characteristic Curve）</strong> 和 <strong>AUC（Area Under the Curve）</strong> 作为主要评估指标。</p>
<h4><strong>1.1 预测分类方式</strong></h4>
<p>模型输出 <strong>每个类别的概率</strong>（地震或爆炸），通过设定 <strong>阈值（Threshold）</strong>，决定测试集中的事件属于 <strong>地震（Earthquake）</strong> 还是 <strong>爆炸（Explosion）</strong>。计算 <strong>混淆矩阵（Confusion Matrix）</strong> 的关键指标：</p>
<ul>
<li><strong>真正例（$TP$，True Positive）</strong>：正确预测的爆炸事件。</li>
<li><strong>真负例（$TN$，True Negative）</strong>：正确预测的地震事件。</li>
<li><strong>假正例（$FP$，False Positive）</strong>：将地震错误分类为爆炸。</li>
<li><strong>假负例（$FN$，False Negative）</strong>：将爆炸错误分类为地震。</li>
</ul>
<h4><strong>1.2 评估指标计算公式</strong></h4>
<ul>
<li><strong>精确率（Precision）</strong>：</li>
</ul>
<p>$$
Precision = \frac{TP}{TP + FP}
$$</p>
<ul>
<li>
<strong>召回率（Recall 或 $TPR$，True Positive Rate）</strong>：</li>
</ul>
<p>$$
TPR = Recall = \frac{TP}{TP + FN}
$$</p>
<ul>
<li>
<strong>假正率（$FPR$，False Positive Rate）</strong>：</li>
</ul>
<p>$$
FPR = \frac{FP}{FP + TN}
$$</p>
<ul>
<li>
<strong>$F1$ 分数（F1-Score）</strong>：</li>
</ul>
<p>$$
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
$$</p>
<h4><strong>1.3 ROC 曲线与 AUC</strong></h4>
<p>通过 <strong>改变阈值</strong>，计算不同点的 <strong>$TPR$ 和 $FPR$</strong>，绘制 <strong>ROC 曲线</strong>。<br>
<strong>AUC（曲线下面积）</strong> 代表分类器在不同阈值下的整体性能：</p>
<ul>
<li>
<strong>$AUC$ 值范围：$0 - 1$</strong>，值越大表示分类器性能越优。</li>
<li>
<strong>$AUC = 1$</strong> 表示完美分类，<strong>$AUC = 0.5$</strong> 表示随机分类。</li>
</ul>
<hr>
<h3><strong>2. 多分类任务的评估方法</strong></h3>
<p>对于 <strong>多分类任务（如地震、爆炸、地表事件）</strong>，我们采用 <strong>一对多（One-vs-Rest）</strong> 方法，将其转换为多个 <strong>二分类问题</strong>。</p>
<h4><strong>2.1 One-vs-Rest 方法</strong></h4>
<p>我们对 <strong>每个类别单独计算 ROC 曲线和 AUC</strong>，具体方式如下：</p>
<ul>
<li>在 <strong>图 2</strong> 的计算过程中：
<ul>
<li>视 <strong>地震</strong> 为 <strong>正样本（Positive）</strong>，爆炸 &amp; 地表事件为 <strong>负样本（Negative）</strong>。</li>
<li>视 <strong>爆炸</strong> 为 <strong>正样本</strong>，地震 &amp; 地表事件为 <strong>负样本</strong>。</li>
<li>视 <strong>地表事件</strong> 为 <strong>正样本</strong>，地震 &amp; 爆炸为 <strong>负样本</strong>。</li>
</ul>
</li>
<li>
<strong>分别计算 $TP, TN, FP, FN$ 指标</strong>，生成多个二分类 ROC 曲线。</li>
</ul>
<h4><strong>2.2 宏平均（Macro Average）</strong></h4>
<p>我们计算多个类别的 <strong>$AUC$ 值的算术平均值</strong>，作为整体分类性能的衡量指标：</p>
<p>$$<br>
Macro\ Average = \frac{AUC_1 + AUC_2 + AUC_3}{3}<br>
$$<br>
宏平均（Macro Average）能够衡量模型在所有类别上的平均分类能力，确保其不偏向某一特定类别。</p>
<hr>
<h3><strong>3. 结论</strong></h3>
<ul>
<li><strong>二分类任务</strong> 采用 <strong>ROC 曲线和 AUC 评估模型整体性能</strong>，并计算 <strong>Precision、Recall、F1-Score</strong> 等关键指标。</li>
<li><strong>多分类任务</strong> 采用 <strong>One-vs-Rest 方法，将多分类问题转化为多个二分类问题</strong>，分别计算 ROC 曲线和 AUC。</li>
<li><strong>使用宏平均（Macro Average）评估多分类任务的整体性能</strong>，确保模型在所有类别上的分类效果均衡。</li>
</ul>
<h2><strong>附录 B：训练细节（Training Details）</strong></h2>
<h3><strong>1. 训练优化策略</strong></h3>
<p>在训练过程中，<strong>SeisCLIP 采用 ADAM 优化方法（ADAM Optimizer）</strong>，并针对 <strong>不同的训练过程</strong> 采用不同的 <strong>损失函数（Loss Function）、学习率（Learning Rate）、训练轮数（Epochs）和批量大小（Batch Size）</strong>（详见 <strong>表 IV</strong>）。</p>
<h3><strong>2. 训练损失曲线分析</strong></h3>
<p><strong>图 11</strong> 展示了 <strong>预训练（Pretraining）和各下游任务（Downstream Tasks）</strong> 训练集和验证集的 <strong>损失曲线（Loss Curves）</strong>。<br>
所有模型均基于 <strong>验证集（Validation Dataset）上的最佳表现</strong> 进行选择：</p>
<ul>
<li><strong>预训练过程中，模型在第 55 轮（55th Epoch）达到最佳性能</strong>：
<ul>
<li>此时 <strong>损失函数值最低</strong>，模型的 <strong>训练集和验证集精度最高</strong>。</li>
<li>因此，该轮次的模型被选定为 <strong>最终的预训练模型（Final Pre-Trained Model）</strong>。</li>
</ul>
</li>
</ul>
<h3><strong>3. SeisCLIP 性能的关键因素</strong></h3>
<p>SeisCLIP 的 <strong>优异表现（Superior Performance）</strong> 主要归因于其 <strong>预训练编码器（Pre-Trained Encoder）</strong> 具有 <strong>大规模参数量（Substantial Parameter Volume）</strong>：</p>
<ul>
<li>由于编码器已经在 <strong>大量数据上预训练</strong>，它可以 <strong>提取丰富的特征</strong>，从而在下游任务中提供更好的泛化能力。</li>
<li>在具体的 <strong>下游任务（Downstream Tasks）</strong> 中，<strong>解码器（Decoder）部分的参数量明显减少</strong>，降低计算成本，同时保持高性能。</li>
</ul>
<h3><strong>4. 可训练参数对比</strong></h3>
<p>为了评估模型的计算开销，我们对 <strong>不同模型的可训练参数数量（Trainable Parameters）</strong> 进行了比较（详见 <strong>表 V</strong>）。<br>
该分析有助于理解：</p>
<ul>
<li><strong>SeisCLIP 预训练模型的计算量相对较大</strong>，但<strong>下游任务微调时，可训练参数显著减少</strong>。</li>
<li><strong>相比其他基线模型，SeisCLIP 由于预训练的特性，在实际任务中更具计算效率</strong>。</li>
</ul>
<h3><strong>结论</strong></h3>
<ul>
<li><strong>SeisCLIP 采用 ADAM 优化，并针对不同任务调整超参数</strong>（损失函数、学习率、批量大小等）。</li>
<li><strong>训练曲线表明，模型在 55 轮时达到最佳状态，因此该轮模型被选定为最终预训练模型</strong>。</li>
<li><strong>SeisCLIP 预训练编码器的庞大参数量赋予其强大的特征提取能力，使得下游任务可采用更轻量的解码器，提高计算效率</strong>。</li>
<li><strong>不同模型的可训练参数对比（表 V）进一步说明，SeisCLIP 预训练模型可在微调阶段减少参数量，同时保持优异性能</strong>。</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/user-attachments/assets/002465be-d75d-4c69-9d67-df99e1686dc9"><img src="https://github.com/user-attachments/assets/002465be-d75d-4c69-9d67-df99e1686dc9" alt="Image" style="max-width: 100%;"></a></p>
<p><a href="https://ieeexplore.ieee.org/document/10400506" rel="nofollow">Paper Link</a></p></div>
<div style="font-size:small;margin-top:8px;float:right;">转载请注明出处</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://Lszidv.github.io">芜尽</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","Lszidv/Lszidv.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}



</script>
<script>MathJax = {tex: {inlineMath: [["$", "$"]]}};</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</html>
