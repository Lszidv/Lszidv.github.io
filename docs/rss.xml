<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>芜尽</title><link>https://Lszidv.github.io</link><description>Only love can set us free</description><copyright>芜尽</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://avatars.githubusercontent.com/u/160511559?s=400&amp;u=68ec73daff523efd8652079b221d42e446d01cb6&amp;v=4</url><title>avatar</title><link>https://Lszidv.github.io</link></image><lastBuildDate>Mon, 30 Dec 2024 07:21:11 +0000</lastBuildDate><managingEditor>芜尽</managingEditor><ttl>60</ttl><webMaster>芜尽</webMaster><item><title>[Literature Reading]Multichannel analysis of shear wave splitting </title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DMultichannel%20analysis%20of%20shear%20wave%20splitting%20.html</link><description>## Abstract&#13;
科学问题：&#13;
如何联合多个震相提高测量结果的鲁棒性？&#13;
如何在复杂区域有效区分不同的各向异性特征？&#13;
如何处理低信噪比数据并提高结果的稳健性？&#13;
&#13;
## Introduction&#13;
The analysis of shear wave splitting is greatly simplified if the polarization of the incoming wave is known.&#13;
&#13;
#### 方法一：叠加横向分量方法（Stacking the transverse components method）&#13;
- **核心原理**：&#13;
  - 通过叠加多个震相记录的横向分量，找到最大振幅的快波方向和延迟时间。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DMultichannel%20analysis%20of%20shear%20wave%20splitting%20.html</guid><pubDate>Mon, 30 Dec 2024 07:20:51 +0000</pubDate></item><item><title>[Literature Reading]SplitLab</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DSplitLab.html</link><description># SplitLab: 剪切波分裂数据处理环境总结&#13;
&#13;
## 背景与目标&#13;
- 剪切波分裂（Shear Wave Splitting, SWS）是研究地壳和地幔各向异性的重要方法。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DSplitLab.html</guid><pubDate>Thu, 26 Dec 2024 13:37:59 +0000</pubDate></item><item><title>[Literature Reading]splitracer</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5Dsplitracer.html</link><description>## Abstract&#13;
本文提出了一种新型的自动化工具，旨在提高大规模地震数据集的分析效率与客观性。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5Dsplitracer.html</guid><pubDate>Tue, 24 Dec 2024 13:22:42 +0000</pubDate></item><item><title>[Literature Reading]近场地震快慢横波到时差测量离散辨析和改正</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-jin-chang-di-zhen-kuai-man-heng-bo-dao-shi-cha-ce-liang-li-san-bian-xi-he-gai-zheng.html</link><description>## 1. 研究背景与意义&#13;
&#13;
### 1.1 剪切波分裂现象&#13;
- 剪切波（S波）分裂是横波在通过各向异性介质时的一种重要现象。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-jin-chang-di-zhen-kuai-man-heng-bo-dao-shi-cha-ce-liang-li-san-bian-xi-he-gai-zheng.html</guid><pubDate>Tue, 24 Dec 2024 05:50:46 +0000</pubDate></item><item><title>[Review]基于剪切波分裂的地球内部各向异性研究综述</title><link>https://Lszidv.github.io/post/%5BReview%5D-ji-yu-jian-qie-bo-fen-lie-de-di-qiu-nei-bu-ge-xiang-yi-xing-yan-jiu-zong-shu.html</link><description>&#13;
## **1. 地球内部各向异性**&#13;
&#13;
### **1.1 定义**&#13;
- **各向异性**指地球介质的物理和化学属性随方向的不同而变化。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BReview%5D-ji-yu-jian-qie-bo-fen-lie-de-di-qiu-nei-bu-ge-xiang-yi-xing-yan-jiu-zong-shu.html</guid><pubDate>Sun, 22 Dec 2024 03:56:03 +0000</pubDate></item><item><title>[Literature Reading]基于深度卷积神经网络的剪切波分裂质量检测</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-ji-yu-shen-du-juan-ji-shen-jing-wang-luo-de-jian-qie-bo-fen-lie-zhi-liang-jian-ce.html</link><description>## 引言&#13;
&#13;
&amp;emsp;通过测量分裂剪切波的快波极化方向（φ）和慢波延迟时间（δt），可以揭示地下介质的各向异性特征。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-ji-yu-shen-du-juan-ji-shen-jing-wang-luo-de-jian-qie-bo-fen-lie-zhi-liang-jian-ce.html</guid><pubDate>Thu, 19 Dec 2024 13:56:00 +0000</pubDate></item><item><title>[Literature Reading]An automatized XKS-splitting procedure for large data sets: Extension package for SplitRacer and application to the USArray </title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DAn%20automatized%20XKS-splitting%20procedure%20for%20large%20data%20sets-%20Extension%20package%20for%20SplitRacer%20and%20application%20to%20the%20USArray%20.html</link><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DAn%20automatized%20XKS-splitting%20procedure%20for%20large%20data%20sets-%20Extension%20package%20for%20SplitRacer%20and%20application%20to%20the%20USArray%20.html</guid><pubDate>Thu, 19 Dec 2024 06:24:41 +0000</pubDate></item><item><title>[Review]基于深度卷积神经网络的地震震相拾取方法研究</title><link>https://Lszidv.github.io/post/%5BReview%5D-ji-yu-shen-du-juan-ji-shen-jing-wang-luo-de-di-zhen-zhen-xiang-shi-qu-fang-fa-yan-jiu.html</link><description>## 摘要&#13;
1. 研究背景与问题&#13;
地震震相拾取是地震数据自动化处理中至关重要的步骤，主要包括信号检测、震相到时估计和震相识别等过程。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BReview%5D-ji-yu-shen-du-juan-ji-shen-jing-wang-luo-de-di-zhen-zhen-xiang-shi-qu-fang-fa-yan-jiu.html</guid><pubDate>Sat, 14 Dec 2024 12:05:07 +0000</pubDate></item><item><title>[Literature Reading]Automatic measurement of shear wave splitting and applications to time varying anisotropy at Mount Ruapehu volcano, New Zealand</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DAutomatic%20measurement%20of%20shear%20wave%20splitting%20and%20applications%20to%20time%20varying%20anisotropy%20at%20Mount%20Ruapehu%20volcano%2C%20New%20Zealand.html</link><description># MFAST&#13;
&#13;
## Abstract&#13;
自动化流程：仅需人工选择S波到达时间，其他步骤完全自动化。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DAutomatic%20measurement%20of%20shear%20wave%20splitting%20and%20applications%20to%20time%20varying%20anisotropy%20at%20Mount%20Ruapehu%20volcano%2C%20New%20Zealand.html</guid><pubDate>Wed, 11 Dec 2024 06:15:28 +0000</pubDate></item><item><title>[Literature Reading]Using Convolutional Neural Network to Determine Time Window for Analyzing Local Shear-Wave Splitting Measurements</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DUsing%20Convolutional%20Neural%20Network%20to%20Determine%20Time%20Window%20for%20Analyzing%20Local%20Shear-Wave%20Splitting%20Measurements.html</link><description>## Abstract&#13;
```&#13;
研究利用CNN来确定时间窗口的结束位置(e)，并且设定时间窗口从e前0.5秒开始。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DUsing%20Convolutional%20Neural%20Network%20to%20Determine%20Time%20Window%20for%20Analyzing%20Local%20Shear-Wave%20Splitting%20Measurements.html</guid><pubDate>Tue, 10 Dec 2024 13:44:47 +0000</pubDate></item><item><title>[Review]利用多种横波分裂分析方法评估确定各向异性参数</title><link>https://Lszidv.github.io/post/%5BReview%5D-li-yong-duo-zhong-heng-bo-fen-lie-fen-xi-fang-fa-ping-gu-que-ding-ge-xiang-yi-xing-can-shu.html</link><description>## 摘要  &#13;
背景：数据的噪声水平、观测方位分布以及介质的复杂程度都会影响横波分裂分析结果的稳定性和准确性。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BReview%5D-li-yong-duo-zhong-heng-bo-fen-lie-fen-xi-fang-fa-ping-gu-que-ding-ge-xiang-yi-xing-can-shu.html</guid><pubDate>Mon, 09 Dec 2024 05:59:29 +0000</pubDate></item><item><title>[Review]A review of techniques for measuring shear-wave splitting above small earthquakes</title><link>https://Lszidv.github.io/post/%5BReview%5DA%20review%20of%20techniques%20for%20measuring%20shear-wave%20splitting%20above%20small%20earthquakes.html</link><description>## Abstrct&#13;
从传统的手动视觉技术到自动化技术的发展，每种方法的优缺点，并提出了一种结合视觉和自动化技术的半自动化测量方法&#13;
&#13;
## 1. Introduction&#13;
**剪切波分裂的成因与特征**&#13;
&amp;emsp;各向异性介质中（如地下的微裂缝），其中剪切波分裂成两相，分别为快波和慢波，并且它们以不同的速度传播。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BReview%5DA%20review%20of%20techniques%20for%20measuring%20shear-wave%20splitting%20above%20small%20earthquakes.html</guid><pubDate>Mon, 09 Dec 2024 02:22:48 +0000</pubDate></item><item><title>[Review]利用横波分裂分析方法研究地壳各向异性综述</title><link>https://Lszidv.github.io/post/%5BReview%5D-li-yong-heng-bo-fen-lie-fen-xi-fang-fa-yan-jiu-di-ke-ge-xiang-yi-xing-zong-shu.html</link><description> ## &#13;
各向异性定义---起源---地震各向异性，意义---直观表现(S波分裂)---分裂参数---影响因素(主要因素，其他因素)&#13;
```&#13;
主要因素：裂缝或主压应力方向、深部物质流动方向、矿物晶格优势排列方向（LPO）&#13;
其他因素：快慢波的波形差异： 快横波和慢横波波形不同，慢横波的衰减更明显，初动较弱。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BReview%5D-li-yong-heng-bo-fen-lie-fen-xi-fang-fa-yan-jiu-di-ke-ge-xiang-yi-xing-zong-shu.html</guid><pubDate>Thu, 05 Dec 2024 15:36:30 +0000</pubDate></item><item><title>[Literature Reading]Pytheas: An open-source software solution for local shear-wave splitting studies </title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DPytheas-%20An%20open-source%20software%20solution%20for%20local%20shear-wave%20splitting%20studies%20.html</link><description>## Abstract&#13;
提供了包括视觉检查、旋转相关法、特征值法和最小能量法在内的多种分析工具,并通过聚类分析实现自动化处理。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DPytheas-%20An%20open-source%20software%20solution%20for%20local%20shear-wave%20splitting%20studies%20.html</guid><pubDate>Tue, 03 Dec 2024 06:46:04 +0000</pubDate></item><item><title>[Literrture Reading]DeepPhasePick: a method for detecting and picking seismic phases from local earthquakes based on highly optimized convolutional and recurrent deep neural networks</title><link>https://Lszidv.github.io/post/%5BLiterrture%20Reading%5DDeepPhasePick-%20a%20method%20for%20detecting%20and%20picking%20seismic%20phases%20from%20local%20earthquakes%20based%20on%20highly%20optimized%20convolutional%20and%20recurrent%20deep%20neural%20networks.html</link><description>## Summary&#13;
相位检测、识别和初至时间是分析地震数据的基础且重要的常规工作。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterrture%20Reading%5DDeepPhasePick-%20a%20method%20for%20detecting%20and%20picking%20seismic%20phases%20from%20local%20earthquakes%20based%20on%20highly%20optimized%20convolutional%20and%20recurrent%20deep%20neural%20networks.html</guid><pubDate>Thu, 28 Nov 2024 06:53:48 +0000</pubDate></item><item><title>[Literature Reading]近震S波震相实时自动识别方法研究</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-jin-zhen-S-bo-zhen-xiang-shi-shi-zi-dong-shi-bie-fang-fa-yan-jiu.html</link><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-jin-zhen-S-bo-zhen-xiang-shi-shi-zi-dong-shi-bie-fang-fa-yan-jiu.html</guid><pubDate>Thu, 28 Nov 2024 05:43:55 +0000</pubDate></item><item><title>[Literature Reading]兼顾速度和精度的深度神经网络震相拾取</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-jian-gu-su-du-he-jing-du-de-shen-du-shen-jing-wang-luo-zhen-xiang-shi-qu.html</link><description>## 摘要&#13;
  根据地震波形的特点设计了四种具有不同复杂度的深度神经网络改进模型，可以综合具体的精度和速度需求从中选取合适的模型，将改进模型与现有四种到时拾取的深度学模型作对比。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-jian-gu-su-du-he-jing-du-de-shen-du-shen-jing-wang-luo-zhen-xiang-shi-qu.html</guid><pubDate>Wed, 27 Nov 2024 05:27:15 +0000</pubDate></item><item><title>[Literature Reading]卷积神经网络在远-近地震震相拾取中的应用及模型解释</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-juan-ji-shen-jing-wang-luo-zai-yuan---jin-di-zhen-zhen-xiang-shi-qu-zhong-de-ying-yong-ji-mo-xing-jie-shi.html</link><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5D-juan-ji-shen-jing-wang-luo-zai-yuan---jin-di-zhen-zhen-xiang-shi-qu-zhong-de-ying-yong-ji-mo-xing-jie-shi.html</guid><pubDate>Wed, 27 Nov 2024 05:08:12 +0000</pubDate></item><item><title>震相拾取</title><link>https://Lszidv.github.io/post/zhen-xiang-shi-qu.html</link><description>[PhaseNet  &lt;转载&gt;](https://blog.csdn.net/qq_40206371/article/details/129748282?utm_source=chatgpt.com)&#13;
&#13;
&#13;
---&#13;
&#13;
### 震相拾取与自动化技术的研究背景与发展&#13;
&#13;
#### 总结：&#13;
地震震相信息是地震学研究中的重要基础数据，广泛应用于地震定位、震源机制分析和走时层析成像等领域。</description><guid isPermaLink="true">https://Lszidv.github.io/post/zhen-xiang-shi-qu.html</guid><pubDate>Thu, 21 Nov 2024 07:59:49 +0000</pubDate></item><item><title>[Literature Reading] 一种适用于地方震事件的S波到时自动拾取方法</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5D%20-yi-zhong-shi-yong-yu-di-fang-zhen-shi-jian-de-S-bo-dao-shi-zi-dong-shi-qu-fang-fa.html</link><description>##  引言&#13;
&#13;
  S波拾取困难:受到P波尾波及其他转换波震相影响，因此S波的信噪比一般低于P波，拾取的准确度也比较低；&#13;
  现有手动拾取方法：基于极化特征，利用原始地震三分量记录，根据P波和S波在偏振方向上的不同特征（如质点运动的偏振度、线性度等），找到震相突变点，进而确定S波到时。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5D%20-yi-zhong-shi-yong-yu-di-fang-zhen-shi-jian-de-S-bo-dao-shi-zi-dong-shi-qu-fang-fa.html</guid><pubDate>Thu, 21 Nov 2024 07:30:45 +0000</pubDate></item><item><title>[Literature Reading]ES for measuring SWS</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DES%20for%20measuring%20SWS.html</link><description>## Abstract&#13;
  专家系统和模块化设计&#13;
&#13;
## 1.Introduction&#13;
 ```&#13;
人工神经网络（Artificial Neural Networks, 1995）：&#13;
训练神经网络识别剪切波分裂，能够处理复杂的波形。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DES%20for%20measuring%20SWS.html</guid><pubDate>Mon, 18 Nov 2024 02:08:16 +0000</pubDate></item><item><title>[Literature Reading]SWAS: A shear-wave analysis system for semi-automatic measurement of shear-wave splitting above small earthquakes</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DSWAS-%20A%20shear-wave%20analysis%20system%20for%20semi-automatic%20measurement%20of%20shear-wave%20splitting%20above%20small%20earthquakes.html</link><description># SWAS: A shear-wave analysis system for semi-automatic measurement of shear-wave splitting above small earthquakes&#13;
##  Abstract&#13;
   问题：小震剪切波到达复杂，剪切波测量困难&#13;
   方法：开发SAWS专家系统，自动估计快波极化方向和剪切波到时，人工辅助调整（在原始地震图、旋转地震图和极化图之间进行调整）&#13;
   数据：冰岛SIL地震网络数据&#13;
&#13;
 ```&#13;
  里氏震级：基于地震波振幅，在这个标度中，为了使结果不为负数，里克特定义在距离震中100千米处之观测点地 &#13;
  震仪记录到的最大水平位移为1微米（这也是伍德-安德森扭力式地震仪的最大精度）的地震作为0级地震，当地震 &#13;
  仪记录到的最大水平位移小于1微米，震级便为负。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DSWAS-%20A%20shear-wave%20analysis%20system%20for%20semi-automatic%20measurement%20of%20shear-wave%20splitting%20above%20small%20earthquakes.html</guid><pubDate>Fri, 15 Nov 2024 05:03:39 +0000</pubDate></item><item><title>[Literature Reading]Feasibility of Deep Learning in Shear Wave Splitting analysis using Synthetic-Data Training and Waveform Deconvolution</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5DFeasibility%20of%20Deep%20Learning%20in%20Shear%20Wave%20Splitting%20analysis%20using%20Synthetic-Data%20Training%20and%20Waveform%20Deconvolution.html</link><description>## Abstract&#13;
&#13;
背景与传统方法：传统方法通过逆转分裂过程，通过频域和时域操作，最小化波形切向能量，得到分裂参数。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5DFeasibility%20of%20Deep%20Learning%20in%20Shear%20Wave%20Splitting%20analysis%20using%20Synthetic-Data%20Training%20and%20Waveform%20Deconvolution.html</guid><pubDate>Thu, 14 Nov 2024 02:54:56 +0000</pubDate></item><item><title>为什么python类中要使用__init__()特殊方法</title><link>https://Lszidv.github.io/post/wei-shen-me-python-lei-zhong-yao-shi-yong-__init__%28%29-te-shu-fang-fa.html</link><description>今天看到如下代码（一个学习率调度器类），引发了笔者困扰已久的问题：__init__()特殊方法到底有什么用，为什么python类中要使用__init__()特殊方法？&#13;
```&#13;
class LRScheduler():&#13;
	'''&#13;
	Learning rate scheduler. If the validation loss does not decrease for the&#13;
	given number of `patience` epochs, then the learning rate will decrease by&#13;
	by given `factor`.&#13;
	'''&#13;
	def __init__(self, optimizer, patience=7, min_lr=1e-6, factor=0.5):&#13;
		'''&#13;
		new_lr = old_lr * factor&#13;
		:param optimizer: the optimizer we are using&#13;
		:param patience: how many epochs to wait before updating the lr&#13;
		:param min_lr: least lr value to reduce to while updating&#13;
		:param factor: factor by which the lr should be updated&#13;
		'''&#13;
		self.optimizer = optimizer&#13;
		self.patience = patience&#13;
		self.min_lr = min_lr&#13;
		self.factor = factor&#13;
		self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(&#13;
				self.optimizer,&#13;
				mode='min',&#13;
				patience=self.patience,&#13;
				factor=self.factor,&#13;
				min_lr=self.min_lr,&#13;
				verbose=True&#13;
			)&#13;
	def __call__(self, val_loss):&#13;
		self.lr_scheduler.step(val_loss)&#13;
```&#13;
&#13;
__init__是一个特殊方法，解释为类的初始化方法或构造器，功能也就不言而喻了，当创建一个类的实例时，python会自动调用这个方法。</description><guid isPermaLink="true">https://Lszidv.github.io/post/wei-shen-me-python-lei-zhong-yao-shi-yong-__init__%28%29-te-shu-fang-fa.html</guid><pubDate>Thu, 07 Nov 2024 12:11:02 +0000</pubDate></item><item><title>CNN-SWS</title><link>https://Lszidv.github.io/post/CNN-SWS.html</link><description>## 论文“Classification of Teleseismic Shear Wave Splitting Measurements: A Convolutional Neural Network Approach”代码部分&#13;
&#13;
### 文件结构&#13;
```&#13;
CNN-SWS-main/&#13;
├── 1_data/                                # 数据文件夹&#13;
│   ├── Out_Bin/                           # 存储 XKS.out 文件，.out文件包含三列，台站和网络名称（stname_NW）、事件名称（EQ123456789）、测量质量（A 和 B 表示可接受，其余表示不可接受）      &#13;
│   │   ├── PKS.out                       &#13;
│   │   ├── SKK.out&#13;
│   │   └── SKS.out&#13;
│   └── PKSOut/                            # 存储不同台站和事件的波形数据&#13;
│       ├── 109Cxx_TA/                     # 台站文件夹&#13;
│       │   ├── EQ140250514/               # 事件文件夹&#13;
│       │   │   ├── 109Cxx_TA.rl           # 校正径向分量&#13;
│       │   │   ├── 109Cxx_TA.ro           # 原始径向分量&#13;
│       │   │   ├── 109Cxx_TA.tl           # 校正横向分量&#13;
│       │   │   └── 109Cxx_TA.to           # 原始横向分量&#13;
│       │   ├── EQ********/               #其他事件&#13;
│       ├── **************                   # 其他台站文件夹&#13;
│   ├── PKS.list                               # Out_Bin/PKS.out&#13;
│   ├── SKK.list                               # Out_Bin/SKK.out&#13;
│   └── SKS.list                               # Out_Bin/SKS.out&#13;
│&#13;
├── load/                                   # 数据加载和预测文件夹&#13;
│   ├── 2_load/                             # 加载输出文件夹&#13;
│   │   └── Outp/                           # 存放加载预测结果&#13;
│   ├── load.py                             # 数据加载和预测脚本&#13;
│   └── parameter.list                      # 加载过程参数&#13;
│&#13;
├── model/                                  # 模型文件夹&#13;
│   └── CNN_XKS.h5                          # 已训练好的模型权重&#13;
│&#13;
├── train/                                  # 模型训练文件夹&#13;
│   ├── 2_train/                            # 训练输出文件夹&#13;
│   │   ├── CNN_XKS.h5                      # 训练后的模型权重&#13;
│   │   ├── parameters.list                 # 训练过程参数(单独写出来，方便改动)&#13;
│   │   ├── train_64.acc                    # 训练精度记录&#13;
│   │   ├── train_64.loss                   # 训练损失记录&#13;
│   │   ├── train_64.val_acc                # 验证精度记录&#13;
│   │   └── train_64.val_loss               # 验证损失记录&#13;
│   └── train.py                            # 模型训练脚本&#13;
│&#13;
├── test/                                   # 测试文件夹&#13;
│   └── test.py                             # 模型可视化和测试脚本&#13;
│&#13;
├── Do_load.cmd                             # 加载命令脚本&#13;
├── Do_train.cmd                            # 训练命令脚本&#13;
└── README.txt                              # 项目说明文件&#13;
&#13;
&#13;
```&#13;
&#13;
### load.py&#13;
  ```&#13;
import os&#13;
import numpy as np&#13;
from obspy import read&#13;
from keras.models import Sequential&#13;
from keras.layers import Conv1D, ZeroPadding1D, Flatten, Dense&#13;
&#13;
X = []                                                                        # 数据列表&#13;
Y = []                                                                        # 标签列表&#13;
X_nst, Y_nev = [], []                                                       # 台站名和事件名&#13;
input_length = 1000&#13;
&#13;
# 数据和模型加载&#13;
nrt = os.path.normpath('C:/Users/~/S-wave spliting/CNN-SWS-main/1_data')&#13;
nmodel = os.path.normpath('C:/Users/~/S-wave spliting/CNN-SWS-main/model/CNN_XKS.h5')&#13;
# 路径检查&#13;
if not os.path.exists(nrt):&#13;
    raise FileNotFoundError(f'The data root path {nrt} does not exist.')&#13;
if not os.path.exists(nmodel):&#13;
    raise FileNotFoundError(f'The model path {nmodel} does not exist.')&#13;
```&#13;
&#13;
```&#13;
# 读取SAC数据&#13;
XKS = ['PKS', 'SKS', 'SKK']&#13;
&#13;
for k in range(3):&#13;
    XKS_rout = os.path.join(nrt, f'{XKS[k]}.list')               # C:/Users/~/main/1_data/Out_Bin/*.out&#13;
    print(f'Reading {XKS_rout}')&#13;
&#13;
    if not os.path.exists(XKS_rout):&#13;
        raise FileNotFoundError(f'The file {XKS_rout} does not exist.')&#13;
&#13;
# 逐行读取数据&#13;
with open(XKS_rout, 'r') as Pl:&#13;
    for line_Pl in Pl:&#13;
        vals = line_Pl.split()&#13;
        P_rout = os.path.join(nrt, vals[0])                       # 数据根目录nrt ＋ .out文件第一列&#13;
        print(f'Doing: {XKS[k]} {vals[0]}')&#13;
&#13;
        if not os.path.exists(P_rout):&#13;
            raise FileNotFoundError(f'The file {P_rout} does not exist.')&#13;
```&#13;
```&#13;
PKS, y = [], []                                                              # PKS用于储存波形数据，y储存分类标签&#13;
with open(P_rout, 'r') as P:&#13;
    for line in P:&#13;
        vals = line.split()&#13;
        nst = vals[0]                                                       # station name&#13;
        nev = vals[1]                                                      # event name&#13;
&#13;
        # 处理分类标签&#13;
        if vals[2] in ['A', 'B']:&#13;
            y.append(1)&#13;
            y.append(0)&#13;
        else:&#13;
            y.append(0)&#13;
            y.append(1)&#13;
&#13;
```&#13;
```&#13;
&#13;
ncom = ['.ro', '.to', '.rl', '.tl']                                    # 4分量列表    &#13;
components = []&#13;
for i in range(4):&#13;
    ro_rout = os.path.join(nrt, f'{XKS[k]}Out', nst, nev, f'{nst}{ncom[i]}')&#13;
    print(f'Reading file: {ro_rout}')&#13;
&#13;
    if os.path.exists(ro_rout):&#13;
        st = read(ro_rout)&#13;
        components.append(st[0].data[:input_length])   # 截取前input_length个数据&#13;
    else:&#13;
        raise FileNotFoundError(f'The file {ro_rout} does not exist.')&#13;
&#13;
for i in range(input_length):&#13;
    PKS.append(np.array([comp[i] for comp in components]))&#13;
&#13;
X.append(np.array(PKS))                                            # 将4个分量组成的PKS保存到列表X中&#13;
Y.append(np.array(y))                                                # 分类标签保存到Y中&#13;
X_nst.append(f'{nst}_{XKS[k]}_')                                # 台站信息&#13;
Y_nev.append(nev)                                                    # 事件信息&#13;
&#13;
```&#13;
&#13;
```&#13;
# 定义模型&#13;
input_shape = (input_length, 4)&#13;
model = Sequential()&#13;
   # 添加卷积层&#13;
model.add(Conv1D(kernel_size=3, filters=32, input_shape=input_shape, strides=2, activation='relu'))&#13;
model.add(ZeroPadding1D(padding=1))&#13;
model.add(Conv1D(kernel_size=3, filters=32, strides=2, activation='relu'))&#13;
model.add(ZeroPadding1D(padding=1))&#13;
model.add(Conv1D(kernel_size=3, filters=32, strides=2, activation='relu'))&#13;
model.add(ZeroPadding1D(padding=1))&#13;
model.add(Conv1D(kernel_size=3, filters=32, strides=2, activation='relu'))&#13;
model.add(ZeroPadding1D(padding=1))&#13;
model.add(Conv1D(kernel_size=3, filters=32, strides=2, activation='relu'))&#13;
model.add(Flatten())&#13;
model.add(Dense(units=2, activation='softmax'))&#13;
&#13;
# 加载模型权重并进行预测&#13;
model.load_weights(nmodel)&#13;
result = model.predict(np.array(X))&#13;
&#13;
# 保存预测结果&#13;
output_dir = os.path.join('C:/Users/~/S-wave spliting/CNN-SWS-main/load/2_load/Outp')&#13;
os.makedirs(output_dir, exist_ok=True)&#13;
for i in range(len(result)):&#13;
    nst = X_nst[i]                                                                        &#13;
    nev = Y_nev[i]                                                                      &#13;
    res_name = os.path.join(output_dir, f'{nst}_{nev}.res')         &#13;
    y_name = os.path.join(output_dir, f'{nst}_{nev}.y')&#13;
&#13;
    np.savetxt(res_name, result[i])&#13;
    np.savetxt(y_name, Y[i])&#13;
&#13;
print('finish')&#13;
```&#13;
&#13;
&#13;
&#13;
### train.py&#13;
&#13;
```&#13;
import numpy as np&#13;
import matplotlib.pyplot as plt&#13;
import obspy&#13;
import csv&#13;
from obspy import read&#13;
from obspy.taup import TauPyModel&#13;
import os&#13;
from pathlib import Path&#13;
import random&#13;
import keras&#13;
from keras import regularizers&#13;
from keras.models import Sequential&#13;
from keras.layers import Dense, Dropout, Flatten, Conv2D, Conv1D, MaxPooling1D, UpSampling1D, ZeroPadding1D&#13;
&#13;
# 初始化&#13;
X_good, Y_good = [], []&#13;
X_bad, Y_bad = [], []&#13;
X, Y = [], []&#13;
X_rand, Y_rand = [], []&#13;
nst_good, nev_good = [], []&#13;
nst_bad, nev_bad = [], []&#13;
X_nst, Y_nev = [], []&#13;
nst_rand, nev_rand = [], []&#13;
```&#13;
&#13;
```&#13;
# 读取参数文件&#13;
n=0&#13;
with open('parameters.list') as p:&#13;
    for line in p:&#13;
        n += 1&#13;
        vals = line.split()&#13;
        if n == 1: nrt = str(vals[0])&#13;
        if n == 2: batch_size = int(vals[0])&#13;
        if n == 3: epochs = int(vals[0])&#13;
        if n == 4: byn = int(vals[0])&#13;
        if n == 5:&#13;
            ac = int(vals[0])&#13;
            uc = int(vals[1])&#13;
&#13;
```&#13;
&#13;
```&#13;
# 读取SAC数据&#13;
input_length = 1000&#13;
XKS = ['PKS', 'SKS', 'SKK']&#13;
&#13;
for k in range(3):&#13;
    XKS_rout = nrt + str(XKS[k]) + '.list'&#13;
    with open(XKS_rout) as Pl:&#13;
        for line_Pl in Pl:&#13;
            vals = line_Pl.split()&#13;
            P_rout = nrt + str(vals[0])&#13;
            with open(P_rout) as P:&#13;
                for line in P:&#13;
                    PKS, y = [], []&#13;
                    vals = line.split()&#13;
                    nst = vals[0]  # station name&#13;
                    nev = vals[1]  # event name&#13;
                    y = [1, 0] if vals[2] in ['A', 'B'] else [0, 1]&#13;
                    &#13;
                    ncom = ['.ro', '.to', '.rl', '.tl']&#13;
                    for i in range(4):&#13;
                        ro_rout = f'{nrt}{XKS[k]}Out/{nst}/{nev}/{nst}{ncom[i]}'&#13;
                        st = read(ro_rout)&#13;
                        if i == 0: ro = st[0].data&#13;
                        if i == 1: to = st[0].data&#13;
                        if i == 2: rl = st[0].data&#13;
                        if i == 3: tl = st[0].data&#13;
                        &#13;
                    for i in range(input_length):&#13;
                        PKS.append(np.array([ro[i], to[i], rl[i], tl[i]]))&#13;
                    if y[0] == 1:&#13;
                        X_good.append(PKS)&#13;
                        Y_good.append(y)&#13;
                        nst_good.append(f'{nst}_{XKS[k]}_')&#13;
                        nev_good.append(nev)&#13;
                    else:&#13;
                        X_bad.append(PKS)&#13;
                        Y_bad.append(y)&#13;
                        nst_bad.append(f'{nst}_{XKS[k]}_')&#13;
                        nev_bad.append(nev)&#13;
```&#13;
```&#13;
# 数据增强（通过倍增来平衡数据集中的类别数量）&#13;
npts = int(len(X_bad) / len(X_good))&#13;
class_weight = {0: ac, 1: uc}&#13;
if byn == 0: npts = 1&#13;
&#13;
for i in range(npts):&#13;
    for ii in range(len(X_good)):&#13;
        X.append(X_good[ii])&#13;
        Y.append(Y_good[ii])&#13;
        X_nst.append(nst_good[ii])&#13;
        Y_nev.append(nev_good[ii])&#13;
&#13;
for i in range(len(X_bad)):&#13;
    X.append(X_bad[i])&#13;
    Y.append(Y_bad[i])&#13;
    X_nst.append(nst_bad[i])&#13;
    Y_nev.append(nev_bad[i])&#13;
&#13;
# 数据随机化与划分&#13;
rann0 = random.sample(range(len(X)), len(X))&#13;
X_rand = [X[i] for i in rann0]&#13;
Y_rand = [Y[i] for i in rann0]&#13;
x_train, y_train = np.array(X_rand[:int(len(X) * 0.8)]), np.array(Y_rand[:int(len(Y) * 0.8)])&#13;
x_test, y_test = np.array(X_rand[int(len(X) * 0.8):]), np.array(Y_rand[int(len(Y) * 0.8):])&#13;
&#13;
```&#13;
```&#13;
model = Sequential()&#13;
model.add(Conv1D(32, kernel_size=3, strides=2, activation='relu', input_shape=(input_length, 4)))&#13;
model.add(ZeroPadding1D(1))&#13;
# 添加多个卷积层，最终展平成向量并连接到 softmax 输出层&#13;
model.add(Flatten())&#13;
model.add(Dense(2, activation='softmax'))&#13;
&#13;
model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])&#13;
H = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weight, validation_data=(x_test, y_test))&#13;
&#13;
# 可视化训练和验证精度&#13;
fig, ax = plt.subplots()&#13;
plt.plot(H.history['acc'], label='train_acc')&#13;
plt.plot(H.history['val_acc'], label='val_acc')&#13;
plt.legend()&#13;
plt.show()&#13;
&#13;
model.save_weights('CNN_XKS.h5')&#13;
print('Finish')&#13;
&#13;
```&#13;
&#13;
。</description><guid isPermaLink="true">https://Lszidv.github.io/post/CNN-SWS.html</guid><pubDate>Wed, 06 Nov 2024 03:30:02 +0000</pubDate></item><item><title>[Literaturre Reading] Making Reliable Shear-Wave Splitting Measurements</title><link>https://Lszidv.github.io/post/%5BLiteraturre%20Reading%5D%20Making%20Reliable%20Shear-Wave%20Splitting%20Measurements.html</link><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiteraturre%20Reading%5D%20Making%20Reliable%20Shear-Wave%20Splitting%20Measurements.html</guid><pubDate>Mon, 04 Nov 2024 09:06:19 +0000</pubDate></item><item><title>[Literature Reading] Classification of Teleseismic Shear Wave Splitting Measurements: A Convolutional Neural Network Approach</title><link>https://Lszidv.github.io/post/%5BLiterature%20Reading%5D%20Classification%20of%20Teleseismic%20Shear%20Wave%20Splitting%20Measurements-%20A%20Convolutional%20Neural%20Network%20Approach.html</link><description># Classification of Teleseismic Shear Wave Splitting Measurements: A Convolutional Neural Network Approach&#13;
# Abstract&#13;
  剪切波分裂&#13;
  问题：需要可靠的分裂测量数据，目视效率低&#13;
  方法：CNN 人工识别数据训练，合成数据测试，实际数据对比&#13;
  应用：Boardband seismic data recorded in south central Alaska&#13;
&#13;
# 1.Introduction&#13;
  XKS波在各向异性介质中会分裂成两个正交极化的快波和慢波。</description><guid isPermaLink="true">https://Lszidv.github.io/post/%5BLiterature%20Reading%5D%20Classification%20of%20Teleseismic%20Shear%20Wave%20Splitting%20Measurements-%20A%20Convolutional%20Neural%20Network%20Approach.html</guid><pubDate>Mon, 28 Oct 2024 09:40:20 +0000</pubDate></item><item><title>From Here On</title><link>https://Lszidv.github.io/post/From%20Here%20On.html</link><description>My first blog.&#13;
&#13;
。</description><guid isPermaLink="true">https://Lszidv.github.io/post/From%20Here%20On.html</guid><pubDate>Mon, 28 Oct 2024 08:00:54 +0000</pubDate></item></channel></rss>