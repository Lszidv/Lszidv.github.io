## 摘要
  根据地震波形的特点设计了四种具有不同复杂度的深度神经网络改进模型，可以综合具体的精度和速度需求从中选取合适的模型，将改进模型与现有四种到时拾取的深度学模型作对比。

## 引言
  直接输入原始三分量波形，简化预处理步骤
```
全连接网络（FCN）：最早用于震相拾取的神经网络模型是多层感知器（MLP），但其缺乏有效的信号处理能力，难以取得较好的结果。
卷积神经网络（CNN）：能够有效处理波形数据，因此在震相拾取中取得了较好的效果。CNN 通过对波形数据的提取简化了震相到时的处理过程，并且有些结合卷积与全连接网络的算法取得了较高的精度。
编码解码模型（CNN + 解码结构）：采用了卷积反卷积结构，提升了震相拾取的精度，且对噪声具有更强的鲁棒性。该模型借鉴了 U-Net 网络结构。
循环神经网络（RNN）：RNN 设计的初衷是解决自然语言处理中的前后文问题，适合处理震相拾取中需要考虑前后震相信息的任务。特别是双向 RNN（Bi-RNN）和门控循环单元（GRU）能处理更长时间依赖，提升了震相拾取的准确性。
```
问题：未考虑地震波形特点，网络模型过于复杂，关系依赖不明确。
方法：综合考虑模型合理性、精度和速度的深度神经网络模型设计方案

## 1.深度神经网络基本结构
  用于震相拾取的深度学习算法更加接近信号处理算法
1.1  卷积神经网络
```
通过计算输入信号和卷积核之间的相关性来提取特征
边界处理（补零）
可以通过增加步长（卷积核每次滑动的距离）进行下采样（降低维度）
池化层用于对卷积操作后的特征图进行降采样，如最大池化（Max Pooling） 和 平均池化（Average Pooling），其具有平移不变性，在震相拾取中帮助模型识别不同位置的特征
感受野是卷积后的信号中每个采样点所对应原始信号的采样点个数，扩张卷积在卷积核之间插入空洞（零填充）来增加感受野，但计算量和参数数量保持不变。
转置卷积（反卷积）与传统卷积不同，首先进行上采样（即放大图像或信号），然后通过普通卷积对上采样后的图像进行处理。它通常用于编码解码结构中，用于恢复特征图的尺寸。
```
1.2 循环神经网络
```
其网络结构源于马尔可夫（Markov）随机过程，即网络的输出仅取决于上一步的输入
文中使用了 GRU（门控循环单元）作为 RNN 的改进，GRU 是 LSTM（长短时记忆网络）的变种
```
1.3 批正则化层
```
BN层通过将每一层的输入进行归一化处理，使得训练过程更加稳定，缓解了梯度消失问题，并且能够有效避免过拟合
```
## 2.用于震相拾取的深度学习模型
  
