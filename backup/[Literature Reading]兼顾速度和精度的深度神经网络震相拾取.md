## 摘要
  根据地震波形的特点设计了四种具有不同复杂度的深度神经网络改进模型，可以综合具体的精度和速度需求从中选取合适的模型，将改进模型与现有四种到时拾取的深度学模型作对比。

## 引言
  直接输入原始三分量波形，简化预处理步骤
```
全连接网络（FCN）：最早用于震相拾取的神经网络模型是多层感知器（MLP），但其缺乏有效的信号处理能力，难以取得较好的结果。
卷积神经网络（CNN）：能够有效处理波形数据，因此在震相拾取中取得了较好的效果。CNN 通过对波形数据的提取简化了震相到时的处理过程，并且有些结合卷积与全连接网络的算法取得了较高的精度。
编码解码模型（CNN + 解码结构）：采用了卷积反卷积结构，提升了震相拾取的精度，且对噪声具有更强的鲁棒性。该模型借鉴了 U-Net 网络结构。
循环神经网络（RNN）：RNN 设计的初衷是解决自然语言处理中的前后文问题，适合处理震相拾取中需要考虑前后震相信息的任务。特别是双向 RNN（Bi-RNN）和门控循环单元（GRU）能处理更长时间依赖，提升了震相拾取的准确性。
```
问题：未考虑地震波形特点，网络模型过于复杂，关系依赖不明确。
方法：综合考虑模型合理性、精度和速度的深度神经网络模型设计方案

## 1.深度神经网络基本结构
  用于震相拾取的深度学习算法更加接近信号处理算法
1.1  卷积神经网络
```
通过计算输入信号和卷积核之间的相关性来提取特征
边界处理（补零）
可以通过增加步长（卷积核每次滑动的距离）进行下采样（降低维度）
池化层用于对卷积操作后的特征图进行降采样，如最大池化（Max Pooling） 和 平均池化（Average Pooling），其具有平移不变性，在震相拾取中帮助模型识别不同位置的特征
感受野是卷积后的信号中每个采样点所对应原始信号的采样点个数，扩张卷积在卷积核之间插入空洞（零填充）来增加感受野，但计算量和参数数量保持不变。
转置卷积（反卷积）与传统卷积不同，首先进行上采样（即放大图像或信号），然后通过普通卷积对上采样后的图像进行处理。它通常用于编码解码结构中，用于恢复特征图的尺寸。
```
1.2 循环神经网络
```
其网络结构源于马尔可夫（Markov）随机过程，即网络的输出仅取决于上一步的输入
文中使用了 GRU（门控循环单元）作为 RNN 的改进，GRU 是 LSTM（长短时记忆网络）的变种
```
1.3 批正则化层
```
BN层通过将每一层的输入进行归一化处理，使得训练过程更加稳定，缓解了梯度消失问题，并且能够有效避免过拟合
```
## 2.用于震相拾取的深度学习模型
2.1 到时拾取网络的设计与改进
  人脸识别一般使用3×3卷积核，而地震波形特征尺度较大，简单模仿图形处理模型会导致特征拾取不完整
  部分研究使用RNN解决长时间依赖，但RNN训练和推断速度慢，数据量过大时可能难以收敛，而更深的卷积神经网络虽然能提取更复杂的特征，但是会导致计算量的增加
   文中使用Wavenet模型，结合扩张卷积来增加感受野，使用5×5卷积核，由于时一维时序数据处理，所以不会显著增加模型复杂度
  传统CNN未对输入进行筛选和加权（低信噪比低权重），这会让模型易受到噪声干扰，使用门控CNN，计算每个特征的门控值，重要的波形特征中，门控单元会给出接近 1 的输出值，表示这些特征应该被保留和加强；而对于不重要或噪声较大的特征，门控单元的输出接近 0，表示这些特征应被忽略。为减轻梯度消失问题，加快训练过程，加入残差网络结构  
![wavenet结构](https://github.com/user-attachments/assets/8970c417-4ba2-4291-8af0-59b855af61a6)

较大感受野难以捕捉到较小地震的震相特征，将每层输出结果加和，更加符合不同震级震相拾取的需要
为降低计算效率，将其简化为7层，保持纯卷积结构，使用空洞卷积，增加感受野
使用深度可分离卷积，进一步减少参数
```
传统卷积神经网络: K×C1×C2

```
使用LeakyReLU作为激活函数，LeakyReLU＝max（0.25x，x）
此外，在一些半精度和单精度计算效率不同的设备上，使用半精度替代单精度（深度学习数值精度对分类性能影响较少）
